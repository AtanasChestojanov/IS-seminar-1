You said:
I have this assignment, the primary objective is to utilize genetic algorithms
to develop a smart and efficient system for assigning conference papers to reviewers. The system must optimize assignments to maximize overall satisfaction by
aligning reviewer preferences while satisfying all constraints. This optimization
task is essential for conference organizers to automate the paper-review process
effectively, ensuring fairness and efficiency. The task must consider multiple constraints, such as the number of papers each reviewer can handle, the number of
reviews each paper needs, friendship relationships between reviewers to prevent
conflicts of interest (e.g., friends reviewing the same paper), and authorship
constraints where reviewers cannot review papers they have authored.
Dataset Examples
Example 1
• Number of Papers (N): 5
• Number of Reviewers (K): 5
• Reviewer Capacity (R): 3
• Review Requirements per Paper: Each paper must receive between
3 and 5 reviews.
• Authorship Constraints: Certain reviewers have authored specific papers and cannot review them.
Preference Matrix (Pij ):
1
Reviewer \Paper Paper 1 Paper 2 Paper 3 Paper 4 Paper 5
Reviewer 1 5 4 5 3 4
Reviewer 2 4 5 4 5 3
Reviewer 3 3 4 5 4 5
Reviewer 4 5 3 4 5 4
Reviewer 5 4 5 3 4 5
Friendship Matrix (Fii′):
Reviewer \Reviewer Rev 1 Rev 2 Rev 3 Rev 4 Rev 5
Reviewer 1 0 1 0 0 0
Reviewer 2 1 0 1 0 0
Reviewer 3 0 1 0 1 0
Reviewer 4 0 0 1 0 1
Reviewer 5 0 0 0 1 0
Authorship Matrix (Aij ):
Reviewer \Paper Paper 1 Paper 2 Paper 3 Paper 4 Paper 5
Reviewer 1 1 0 0 0 0
Reviewer 2 0 1 0 0 0
Reviewer 3 0 0 1 0 0
Reviewer 4 0 0 0 1 0
Reviewer 5 0 0 0 0 1


 Design a fitness function. 
– The fitness function should evaluate how well an assignment maximizes the preference score while minimizing constraint violations,
including reviewer capacity, paper review requirements, friendship
constraints, and authorship constraints.
ChatGPT said:
ChatGPT
Designing a fitness function for this problem requires a careful balance between maximizing the preference score and penalizing constraint violations. The fitness function will quantify the quality of a given paper-reviewer assignment, guiding the genetic algorithm toward optimal solutions.

Here’s a breakdown of how to design such a fitness function:

Fitness Function Design
The fitness function should:

Maximize the total preference score: The sum of preferences for all assignments.
Minimize constraint violations: Penalize solutions that violate capacity, review requirements, friendship, or authorship constraints.
Mathematical Representation
Let:

𝐴
[
𝑖
]
[
𝑗
]
=
1
A[i][j]=1 if reviewer 
𝑖
i is assigned to paper 
𝑗
j, otherwise 
0
0.
𝑃
[
𝑖
]
[
𝑗
]
P[i][j]: Preference score of reviewer 
𝑖
i for paper 
𝑗
j.
𝐶
[
𝑖
]
C[i]: Maximum capacity of reviewer 
𝑖
i.
𝑅
[
𝑗
]
R[j]: Review requirements for paper 
𝑗
j (between 
min_reviews_per_paper
min_reviews_per_paper and 
max_reviews_per_paper
max_reviews_per_paper).
𝐹
[
𝑖
]
[
𝑘
]
F[i][k]: Friendship constraint between reviewers 
𝑖
i and 
𝑘
k (
1
1 if friends, 
0
0 otherwise).
𝐴
𝑈
[
𝑖
]
[
𝑗
]
AU[i][j]: Authorship constraint (
1
1 if reviewer 
𝑖
i authored paper 
𝑗
j, otherwise 
0
0).
The fitness function 
𝑓
f for an assignment 
𝐴
A can be written as:

𝑓
(
𝐴
)
=
Total Preference Score
−
Penalty for Violations
f(A)=Total Preference Score−Penalty for Violations
Steps to Compute the Fitness Function
1. Total Preference Score
Preference Score
=
∑
𝑖
=
1
𝑁
∑
𝑗
=
1
𝑀
𝐴
[
𝑖
]
[
𝑗
]
⋅
𝑃
[
𝑖
]
[
𝑗
]
Preference Score= 
i=1
∑
N
​
  
j=1
∑
M
​
 A[i][j]⋅P[i][j]
2. Penalty for Violations
a) Reviewer Capacity Constraint: Ensure each reviewer doesn't exceed their capacity 
𝐶
[
𝑖
]
C[i]:

Capacity Violation
=
∑
𝑖
=
1
𝑁
max
⁡
(
0
,
∑
𝑗
=
1
𝑀
𝐴
[
𝑖
]
[
𝑗
]
−
𝐶
[
𝑖
]
)
Capacity Violation= 
i=1
∑
N
​
 max(0, 
j=1
∑
M
​
 A[i][j]−C[i])
b) Paper Review Requirement Constraint: Ensure each paper receives between 
min_reviews_per_paper
min_reviews_per_paper and 
max_reviews_per_paper
max_reviews_per_paper:

Review Violation
=
∑
𝑗
=
1
𝑀
(
max
⁡
(
0
,
min_reviews_per_paper
−
∑
𝑖
=
1
𝑁
𝐴
[
𝑖
]
[
𝑗
]
)
+
max
⁡
(
0
,
∑
𝑖
=
1
𝑁
𝐴
[
𝑖
]
[
𝑗
]
−
max_reviews_per_paper
)
)
Review Violation= 
j=1
∑
M
​
 (max(0,min_reviews_per_paper− 
i=1
∑
N
​
 A[i][j])+max(0, 
i=1
∑
N
​
 A[i][j]−max_reviews_per_paper))
c) Friendship Constraint: Prevent friends from reviewing the same paper:

Friendship Violation
=
∑
𝑗
=
1
𝑀
∑
𝑖
=
1
𝑁
∑
𝑘
=
1
𝑁
𝐹
[
𝑖
]
[
𝑘
]
⋅
𝐴
[
𝑖
]
[
𝑗
]
⋅
𝐴
[
𝑘
]
[
𝑗
]
Friendship Violation= 
j=1
∑
M
​
  
i=1
∑
N
​
  
k=1
∑
N
​
 F[i][k]⋅A[i][j]⋅A[k][j]
d) Authorship Constraint: Ensure reviewers don't review papers they authored:

Authorship Violation
=
∑
𝑖
=
1
𝑁
∑
𝑗
=
1
𝑀
𝐴
[
𝑖
]
[
𝑗
]
⋅
𝐴
𝑈
[
𝑖
]
[
𝑗
]
Authorship Violation= 
i=1
∑
N
​
  
j=1
∑
M
​
 A[i][j]⋅AU[i][j]
3. Combine Terms into Fitness Function
Let 
𝑤
1
,
𝑤
2
,
𝑤
3
,
𝑤
4
w 
1
​
 ,w 
2
​
 ,w 
3
​
 ,w 
4
​
  be weights for the penalties to balance the optimization objectives.

𝑓
(
𝐴
)
=
(
∑
𝑖
=
1
𝑁
∑
𝑗
=
1
𝑀
𝐴
[
𝑖
]
[
𝑗
]
⋅
𝑃
[
𝑖
]
[
𝑗
]
)
−
𝑤
1
⋅
Capacity Violation
−
𝑤
2
⋅
Review Violation
−
𝑤
3
⋅
Friendship Violation
−
𝑤
4
⋅
Authorship Violation
f(A)=( 
i=1
∑
N
​
  
j=1
∑
M
​
 A[i][j]⋅P[i][j])−w 
1
​
 ⋅Capacity Violation−w 
2
​
 ⋅Review Violation−w 
3
​
 ⋅Friendship Violation−w 
4
​
 ⋅Authorship Violation
Key Considerations
Weights 
𝑤
1
,
𝑤
2
,
𝑤
3
,
𝑤
4
w 
1
​
 ,w 
2
​
 ,w 
3
​
 ,w 
4
​
 :
Start with equal weights and adjust based on importance (e.g., friendship and authorship violations might have higher penalties).
Penalty Scaling:
Ensure penalties are large enough to discourage invalid solutions but not so large that minor violations overwhelm preference maximization.
Implementation Example in Python
Here’s how you could implement this fitness function:

python
Copy code
import numpy as np

def fitness_function(assignment, preferences, capacity, min_reviews, max_reviews, friendships, authorship):
    N, M = preferences.shape  # N reviewers, M papers

    # Total Preference Score
    preference_score = np.sum(assignment * preferences)

    # Capacity Violation
    capacity_violation = np.sum(np.maximum(0, np.sum(assignment, axis=1) - capacity))

    # Review Violation
    reviews_per_paper = np.sum(assignment, axis=0)
    review_violation = np.sum(np.maximum(0, min_reviews - reviews_per_paper)) + \
                       np.sum(np.maximum(0, reviews_per_paper - max_reviews))

    # Friendship Violation
    friendship_violation = 0
    for i in range(N):
        for k in range(N):
            if friendships[i][k] == 1:
                friendship_violation += np.sum(assignment[i] * assignment[k])

    # Authorship Violation
    authorship_violation = np.sum(assignment * authorship)

    # Weights for penalties
    w1, w2, w3, w4 = 10, 10, 50, 50

    # Fitness
    fitness = preference_score - (w1 * capacity_violation + w2 * review_violation +
                                   w3 * friendship_violation + w4 * authorship_violation)
    return fitness
Usage
Input:
assignment: Binary matrix (N reviewers × M papers).
preferences: Preference matrix.
capacity: Array of reviewer capacities.
min_reviews, max_reviews: Scalars for review constraints.
friendships: Friendship matrix.
authorship: Authorship matrix.
Output:
A scalar fitness value for the given assignment.
This fitness function effectively balances preferences and constraints, providing a robust foundation for your genetic algorithm.







You said:
N, M = preferences.shape \# N reviewers, M papers

do we need the M
ChatGPT said:
ChatGPT
Yes, you need both 
𝑁
N (the number of reviewers) and 
𝑀
M (the number of papers) from preferences.shape because the dimensions of the problem are critical for iterating over the correct indices.

𝑁
N determines the number of rows in the assignment matrix (reviewers).
𝑀
M determines the number of columns in the assignment matrix (papers).
When designing the fitness function, you need 
𝑀
M specifically to:

Iterate over papers when calculating constraints like review requirements.
Access the preference matrix, which is 
𝑁
×
𝑀
N×M.
Without 
𝑀
M, you wouldn’t know how many papers are involved, which is essential for ensuring that all papers meet the review requirements and for managing assignments correctly.

If you're confident that the number of papers is constant and doesn't change, you could hardcode 
𝑀
M. However, keeping it dynamic via preferences.shape ensures flexibility when working with datasets of different sizes. This is especially useful if you later scale the system to handle more or fewer papers.






You said:
yes, but yoouo dont use M in your code
ChatGPT said:
ChatGPT
You're absolutely right! In the code snippet, while 
𝑀
M is mentioned, it isn't explicitly used because operations like np.sum and array indexing naturally handle the dimensions of the matrices. I'll clarify where 
𝑀
M would actually be used and how we can adjust the explanation.

Adjusted Explanation of the Code
In the provided code:

𝑀
M is implicitly used whenever we calculate sums along axes, such as:
np.sum(assignment, axis=0) (summing over reviewers to get the number of reviews per paper).
assignment * preferences (element-wise multiplication between matrices).
These operations inherently consider the second dimension of the matrix, which corresponds to 
𝑀
M.
Simplified Version
Since the operations don’t explicitly iterate over 
𝑀
M, you could simplify the explanation and remove the explicit mention of 
𝑀
M from the variable initialization:

python
Copy code
def fitness_function(assignment, preferences, capacity, min_reviews, max_reviews, friendships, authorship):
    # Total Preference Score
    preference_score = np.sum(assignment * preferences)

    # Capacity Violation
    capacity_violation = np.sum(np.maximum(0, np.sum(assignment, axis=1) - capacity))

    # Review Violation
    reviews_per_paper = np.sum(assignment, axis=0)
    review_violation = np.sum(np.maximum(0, min_reviews - reviews_per_paper)) + \
                       np.sum(np.maximum(0, reviews_per_paper - max_reviews))

    # Friendship Violation
    friendship_violation = 0
    for i in range(len(friendships)):
        for k in range(len(friendships)):
            if friendships[i][k] == 1:
                friendship_violation += np.sum(assignment[i] * assignment[k])

    # Authorship Violation
    authorship_violation = np.sum(assignment * authorship)

    # Weights for penalties
    w1, w2, w3, w4 = 10, 10, 50, 50

    # Fitness
    fitness = preference_score - (w1 * capacity_violation + w2 * review_violation +
                                   w3 * friendship_violation + w4 * authorship_violation)
    return fitness
Why We Don’t Explicitly Use 
𝑀
M
The assignment, preferences, friendships, and authorship matrices encode 
𝑁
N and 
𝑀
M as their dimensions.
Operations like np.sum along axis=0 or axis=1 handle the dimensions directly, making explicit loops or mentions of 
𝑀
M unnecessary.
When You Would Use 
𝑀
M
Explicit reference to 
𝑀
M might be required if:

You are iterating manually over papers (e.g., to apply custom logic to each paper).
You want to validate the dimensions of the input matrices to ensure they conform to 
𝑁
×
𝑀
N×M.
For example:

python
Copy code
if assignment.shape != preferences.shape:
    raise ValueError("Assignment and preference matrices must have the same dimensions.")
This ensures 
𝑀
M is consistent across inputs.

Conclusion
While 
𝑀
M isn't explicitly used in the original implementation, it remains a conceptual part of the problem. If the code doesn’t need manual iteration over papers, 
𝑀
M can be inferred from the shape of the matrices.






You said:
you also know that a reviewer mustn't review a friend's paper
ChatGPT said:
ChatGPT
You're absolutely correct—reviewers should not review papers assigned to their friends, and this is an important constraint to include in the fitness function.

To handle the friendship constraint, we need to ensure that if two reviewers are friends, they do not review the same paper. This can be implemented as an additional violation term in the fitness function.

Updated Fitness Function with Friendship Constraint
Here’s how the friendship violation is handled:

Friendship Matrix Interpretation:

If friendships[i][j] == 1, then reviewers i and j are friends.
The fitness function should penalize assignments where i and j both review the same paper.
Implementation: Use the assignment matrix to identify overlaps in paper assignments for friends.

python
Copy code
def fitness_function(assignment, preferences, capacity, min_reviews, max_reviews, friendships, authorship):
    # Total Preference Score
    preference_score = np.sum(assignment * preferences)

    # Capacity Violation
    capacity_violation = np.sum(np.maximum(0, np.sum(assignment, axis=1) - capacity))

    # Review Violation
    reviews_per_paper = np.sum(assignment, axis=0)
    review_violation = np.sum(np.maximum(0, min_reviews - reviews_per_paper)) + \
                       np.sum(np.maximum(0, reviews_per_paper - max_reviews))

    # Friendship Violation
    friendship_violation = 0
    for i in range(len(friendships)):
        for j in range(len(friendships)):
            if friendships[i][j] == 1:
                # Penalize if both friends review the same paper
                friendship_violation += np.sum(assignment[i] * assignment[j])

    # Authorship Violation
    authorship_violation = np.sum(assignment * authorship)

    # Weights for penalties
    w1, w2, w3, w4 = 10, 10, 50, 50

    # Fitness
    fitness = preference_score - (w1 * capacity_violation + w2 * review_violation +
                                   w3 * friendship_violation + w4 * authorship_violation)
    return fitness
Key Explanation
1. Friendship Violation:
The term:

python
Copy code
friendship_violation += np.sum(assignment[i] * assignment[j])
assignment[i] * assignment[j] gives a vector where:
The element is 1 if both i and j are assigned to the same paper.
np.sum(assignment[i] * assignment[j]) counts the number of papers reviewed by both i and j.
2. Why Include This?
This penalizes cases where friends review the same paper, ensuring fairness and preventing conflicts of interest.

Testing the Fitness Function
To ensure correctness, test the function with various configurations of friendships, assignment, and preferences. Here's an example:

python
Copy code
# Example matrices
assignment = np.array([[1, 0, 0, 1, 0],  # Reviewer 1 reviews Paper 1 and 4
                       [0, 1, 0, 1, 0],  # Reviewer 2 reviews Paper 2 and 4
                       [0, 0, 1, 0, 1],  # Reviewer 3 reviews Paper 3 and 5
                       [1, 0, 0, 0, 1],  # Reviewer 4 reviews Paper 1 and 5
                       [0, 1, 1, 0, 0]]) # Reviewer 5 reviews Paper 2 and 3

friendships = np.array([[0, 1, 0, 0, 0],  # Reviewer 1 is friends with Reviewer 2
                        [1, 0, 1, 0, 0],  # Reviewer 2 is friends with Reviewers 1 and 3
                        [0, 1, 0, 0, 0],  # Reviewer 3 is friends with Reviewer 2
                        [0, 0, 0, 0, 1],  # Reviewer 4 is friends with Reviewer 5
                        [0, 0, 0, 1, 0]]) # Reviewer 5 is friends with Reviewer 4

preferences = np.array([[5, 4, 5, 3, 4],
                        [4, 5, 4, 5, 3],
                        [3, 4, 5, 4, 5],
                        [5, 3, 4, 5, 4],
                        [4, 5, 3, 4, 5]])

authorship = np.zeros((5, 5))

# Run the fitness function
fitness = fitness_function(assignment, preferences, capacity=3, min_reviews=3, max_reviews=5,
                           friendships=friendships, authorship=authorship)
print(f"Fitness: {fitness}")
Conclusion
This updated fitness function now penalizes any assignments that violate friendship constraints, ensuring fairness in the reviewer-paper assignment process. Let me know if you'd like further refinements!






You said:
but also if me and you are friends i cant review your paper
ChatGPT said:
ChatGPT
Ah, I see! You're pointing out an additional nuance: a reviewer should not review papers authored by their friends. This adds another layer of the friendship constraint, ensuring that the review process avoids conflicts of interest beyond just avoiding joint reviews of the same paper.

This constraint can be implemented by combining the friendship matrix and the authorship matrix. Here's how:

Logic for "Friends Shouldn't Review Each Other's Papers"
Friendship Matrix (friendships):

friendships[i][j] == 1 means reviewer i and reviewer j are friends.
Authorship Matrix (authorship):

authorship[j][p] == 1 means reviewer j authored paper p.
Avoid Reviewing Friend's Papers:

If friendships[i][j] == 1 and authorship[j][p] == 1, reviewer i should not review paper p.
Implementation:

Calculate a derived constraint matrix (friends_authorship) using the friendships and authorship matrices.
This matrix flags papers authored by any friends of each reviewer.
Penalize any violation where a reviewer is assigned to review such papers.
Updated Fitness Function
Here’s the revised function:

python
Copy code
def fitness_function(assignment, preferences, capacity, min_reviews, max_reviews, friendships, authorship):
    # Total Preference Score
    preference_score = np.sum(assignment * preferences)

    # Capacity Violation
    capacity_violation = np.sum(np.maximum(0, np.sum(assignment, axis=1) - capacity))

    # Review Violations
    reviews_per_paper = np.sum(assignment, axis=0)
    review_violation = np.sum(np.maximum(0, min_reviews - reviews_per_paper)) + \
                       np.sum(np.maximum(0, reviews_per_paper - max_reviews))

    # Friendship Joint Review Violation
    friendship_violation = 0
    for i in range(len(friendships)):
        for j in range(len(friendships)):
            if friendships[i][j] == 1:
                # Penalize if both friends review the same paper
                friendship_violation += np.sum(assignment[i] * assignment[j])

    # Friends Reviewing Each Other's Papers
    friends_authorship_violation = 0
    num_reviewers, num_papers = assignment.shape
    for reviewer in range(num_reviewers):
        for paper in range(num_papers):
            # Check if any of the reviewer's friends authored the paper
            for friend in range(num_reviewers):
                if friendships[reviewer][friend] == 1 and authorship[friend][paper] == 1:
                    # Penalize if the reviewer is assigned to the paper
                    friends_authorship_violation += assignment[reviewer][paper]

    # Authorship Violation
    authorship_violation = np.sum(assignment * authorship)

    # Weights for penalties
    w1, w2, w3, w4, w5 = 10, 10, 50, 50, 50

    # Fitness
    fitness = preference_score - (w1 * capacity_violation + w2 * review_violation +
                                   w3 * friendship_violation + w4 * friends_authorship_violation +
                                   w5 * authorship_violation)
    return fitness
Key Updates
friends_authorship_violation:

Checks if a reviewer is assigned to a paper authored by any of their friends.
Penalized similarly to other constraint violations.
Combining friendships and authorship:

friendships[reviewer][friend] == 1 and authorship[friend][paper] == 1 together identify invalid assignments.
Testing the Enhanced Fitness Function
Here’s an example test case to ensure correctness:

python
Copy code
# Example matrices
assignment = np.array([[1, 0, 0, 1, 0],  # Reviewer 1 reviews Paper 1 and 4
                       [0, 1, 0, 1, 0],  # Reviewer 2 reviews Paper 2 and 4
                       [0, 0, 1, 0, 1],  # Reviewer 3 reviews Paper 3 and 5
                       [1, 0, 0, 0, 1],  # Reviewer 4 reviews Paper 1 and 5
                       [0, 1, 1, 0, 0]]) # Reviewer 5 reviews Paper 2 and 3

friendships = np.array([[0, 1, 0, 0, 0],  # Reviewer 1 is friends with Reviewer 2
                        [1, 0, 1, 0, 0],  # Reviewer 2 is friends with Reviewers 1 and 3
                        [0, 1, 0, 0, 0],  # Reviewer 3 is friends with Reviewer 2
                        [0, 0, 0, 0, 1],  # Reviewer 4 is friends with Reviewer 5
                        [0, 0, 0, 1, 0]]) # Reviewer 5 is friends with Reviewer 4

preferences = np.array([[5, 4, 5, 3, 4],
                        [4, 5, 4, 5, 3],
                        [3, 4, 5, 4, 5],
                        [5, 3, 4, 5, 4],
                        [4, 5, 3, 4, 5]])

authorship = np.array([[1, 0, 0, 0, 0],  # Reviewer 1 authored Paper 1
                       [0, 1, 0, 0, 0],  # Reviewer 2 authored Paper 2
                       [0, 0, 1, 0, 0],  # Reviewer 3 authored Paper 3
                       [0, 0, 0, 1, 0],  # Reviewer 4 authored Paper 4
                       [0, 0, 0, 0, 1]]) # Reviewer 5 authored Paper 5

# Run the fitness function
fitness = fitness_function(assignment, preferences, capacity=3, min_reviews=3, max_reviews=5,
                           friendships=friendships, authorship=authorship)
print(f"Fitness: {fitness}")
Summary
This updated fitness function incorporates the constraint that reviewers should not review papers authored by their friends. It ensures fairness and avoids potential conflicts of interest in the reviewer-paper assignment process. Let me know if you’d like to refine it further!






You said:
i need n x m matrix with random zeros and ones but the there shouldnt be more that K ones in a row, and there should be at least S ones in a column
ChatGPT said:
ChatGPT
To generate an 
𝑛
×
𝑚
n×m matrix with random zeros and ones, where no row contains more than 
𝐾
K ones and each column has at least 
𝑆
S ones, we can follow these steps:

Initialize an empty matrix: Start with an 
𝑛
×
𝑚
n×m matrix filled with zeros.
Add ones row by row: For each row, randomly place up to 
𝐾
K ones while ensuring no column constraint is violated.
Check column constraints: If after filling rows, some columns have fewer than 
𝑆
S ones, randomly add ones to those columns without exceeding 
𝐾
K ones per row.
Here's the Python implementation:

Code
python
Copy code
import numpy as np

def generate_matrix(n, m, K, S):
    # Initialize the matrix with zeros
    matrix = np.zeros((n, m), dtype=int)
    
    # Fill the matrix ensuring no more than K ones per row
    for i in range(n):
        ones_to_place = np.random.randint(0, K + 1)  # Randomly decide how many ones to place (up to K)
        columns = np.random.choice(m, ones_to_place, replace=False)  # Randomly select columns
        matrix[i, columns] = 1
    
    # Ensure at least S ones in each column
    for j in range(m):
        current_ones = np.sum(matrix[:, j])
        if current_ones < S:
            additional_ones_needed = S - current_ones
            available_rows = [i for i in range(n) if matrix[i, j] == 0 and np.sum(matrix[i, :]) < K]
            if len(available_rows) < additional_ones_needed:
                raise ValueError(f"Cannot satisfy constraints for column {j}.")
            
            # Randomly add ones to meet the column constraint
            rows_to_fill = np.random.choice(available_rows, additional_ones_needed, replace=False)
            for row in rows_to_fill:
                matrix[row, j] = 1
    
    return matrix

# Example Usage
n, m, K, S = 6, 8, 4, 3  # n rows, m columns, max K ones per row, min S ones per column
matrix = generate_matrix(n, m, K, S)
print(matrix)
Explanation
Row Constraints:
The function ensures that no row exceeds 
𝐾
K ones by randomly choosing up to 
𝐾
K column indices to set to one for each row.
Column Constraints:
After populating the matrix row by row, it verifies that each column has at least 
𝑆
S ones. If not, it randomly assigns ones to columns while respecting the row constraint (
𝐾
K).
Output Example
For 
𝑛
=
6
n=6, 
𝑚
=
8
m=8, 
𝐾
=
4
K=4, 
𝑆
=
3
S=3:

css
Copy code
[[1 0 0 1 0 1 1 0]
 [1 1 1 0 0 0 1 0]
 [1 0 0 1 1 0 1 0]
 [0 0 1 0 1 0 1 1]
 [1 1 0 1 0 1 0 0]
 [0 1 1 0 1 1 0 1]]
Row constraint: Each row has at most 4 ones.
Column constraint: Each column has at least 3 ones.
Let me know if you need further adjustments!






You said:
np.random.randint

replace it with "numpy.random.Generator
ChatGPT said:
ChatGPT
To replace numpy.random.randint and other related random functions with numpy.random.Generator, you need to use the numpy.random.default_rng to create a random generator instance. Here's how to modify the code to use numpy.random.Generator:

Updated Code
python
Copy code
import numpy as np

def generate_matrix(n, m, K, S):
    rng = np.random.default_rng()  # Create a random generator instance
    
    # Initialize the matrix with zeros
    matrix = np.zeros((n, m), dtype=int)
    
    # Fill the matrix ensuring no more than K ones per row
    for i in range(n):
        ones_to_place = rng.integers(0, K + 1)  # Randomly decide how many ones to place (up to K)
        columns = rng.choice(m, ones_to_place, replace=False)  # Randomly select columns
        matrix[i, columns] = 1
    
    # Ensure at least S ones in each column
    for j in range(m):
        current_ones = np.sum(matrix[:, j])
        if current_ones < S:
            additional_ones_needed = S - current_ones
            available_rows = [i for i in range(n) if matrix[i, j] == 0 and np.sum(matrix[i, :]) < K]
            if len(available_rows) < additional_ones_needed:
                raise ValueError(f"Cannot satisfy constraints for column {j}.")
            
            # Randomly add ones to meet the column constraint
            rows_to_fill = rng.choice(available_rows, additional_ones_needed, replace=False)
            for row in rows_to_fill:
                matrix[row, j] = 1
    
    return matrix

# Example Usage
n, m, K, S = 6, 8, 4, 3  # n rows, m columns, max K ones per row, min S ones per column
matrix = generate_matrix(n, m, K, S)
print(matrix)
Changes
Random Generator Creation:

Created a random generator instance: rng = np.random.default_rng().
Replace np.random.randint:

Used rng.integers(low, high) instead of np.random.randint.
Replace np.random.choice:

Used rng.choice for selecting random elements.
Output Example
The output remains the same but uses the numpy.random.Generator API for better reproducibility and control.

Let me know if you'd like additional features like a fixed random seed!






You said:
rng = np.random.default\_rng()

how to provide a seed for this random generator
ChatGPT said:
ChatGPT
To provide a seed for the random generator when using numpy.random.default_rng, pass the seed value as an argument during the generator's creation. This ensures reproducibility of results.

Here’s how to modify the code to include a seed:

python
Copy code
import numpy as np

def generate_matrix(n, m, K, S, seed=None):
    rng = np.random.default_rng(seed)  # Create a random generator instance with a seed
    
    # Initialize the matrix with zeros
    matrix = np.zeros((n, m), dtype=int)
    
    # Fill the matrix ensuring no more than K ones per row
    for i in range(n):
        ones_to_place = rng.integers(0, K + 1)  # Randomly decide how many ones to place (up to K)
        columns = rng.choice(m, ones_to_place, replace=False)  # Randomly select columns
        matrix[i, columns] = 1
    
    # Ensure at least S ones in each column
    for j in range(m):
        current_ones = np.sum(matrix[:, j])
        if current_ones < S:
            additional_ones_needed = S - current_ones
            available_rows = [i for i in range(n) if matrix[i, j] == 0 and np.sum(matrix[i, :]) < K]
            if len(available_rows) < additional_ones_needed:
                raise ValueError(f"Cannot satisfy constraints for column {j}.")
            
            # Randomly add ones to meet the column constraint
            rows_to_fill = rng.choice(available_rows, additional_ones_needed, replace=False)
            for row in rows_to_fill:
                matrix[row, j] = 1
    
    return matrix

# Example Usage with Seed
n, m, K, S = 6, 8, 4, 3  # n rows, m columns, max K ones per row, min S ones per column
seed = 42  # Define a seed for reproducibility
matrix = generate_matrix(n, m, K, S, seed=seed)
print(matrix)
Explanation of Seed Usage
seed Parameter: You can pass any integer to the seed parameter. Using the same seed ensures the same random values are generated across runs.
Default Behavior: If seed=None, the generator will produce non-deterministic results based on the current system time or other randomness sources.
Output Example with Seed
Running the above code with seed=42 will always produce the same matrix for the given input parameters (n, m, K, and S). Change the seed to generate a different reproducible output.









You said:
ds = pd.read_json(file_path)

how to print it in more readable table?
ChatGPT said:
ChatGPT
To print the DataFrame in a more readable table format in Python using Pandas, you can use the pd.DataFrame's built-in functionality or libraries like tabulate for enhanced formatting. Here are a few methods:

1. Using pd.DataFrame.head() (for the first few rows):
This is useful if the dataset is large and you just want to check the first few rows of the DataFrame.

python
Copy code
import pandas as pd

# Load the dataset
ds = pd.read_json(file_path)

# Print the first 5 rows of the DataFrame
print(ds.head())
2. Using tabulate for better formatting:
The tabulate library formats the DataFrame into a readable table. First, install tabulate if you haven't already:

bash
Copy code
pip install tabulate
Then, you can use the following code:

python
Copy code
import pandas as pd
from tabulate import tabulate

# Load the dataset
ds = pd.read_json(file_path)

# Print the entire DataFrame in a readable table format
print(tabulate(ds, headers='keys', tablefmt='pretty', showindex=False))
3. Using pandas.set_option() for better display settings:
If you want to adjust the display options, you can modify Pandas' settings to make the DataFrame more readable.

python
Copy code
import pandas as pd

# Set Pandas display options for better readability
pd.set_option('display.max_rows', 10)  # Adjust as needed (number of rows to display)
pd.set_option('display.max_columns', None)  # Display all columns

# Load the dataset
ds = pd.read_json(file_path)

# Print the dataset
print(ds)
4. Using prettytable (another formatting option):
prettytable is another option for pretty-printing tables.

First, install the library:

bash
Copy code
pip install prettytable
Then, use it like this:

python
Copy code
import pandas as pd
from prettytable import PrettyTable

# Load the dataset
ds = pd.read_json(file_path)

# Convert DataFrame to PrettyTable format
table = PrettyTable(ds.columns)
for row in ds.values:
    table.add_row(row)

# Print the table
print(table)
These methods should help you print the DataFrame in a more readable format depending on your needs.






You said:
in jupyter notebook when you just type the name in this example ds you get good presentation, how to get that result with print?
ChatGPT said:
ChatGPT
In a Jupyter notebook, simply typing the variable name like ds and evaluating it will automatically display the DataFrame in a nicely formatted table. However, when you use print(ds), it outputs the raw string representation of the DataFrame, which can be less readable.

To replicate the Jupyter notebook's default display in a script or when using print(), you can use the display() function from IPython, which provides a richer output similar to the notebook's automatic display.

Here's how to use it:

python
Copy code
from IPython.display import display
import pandas as pd

# Load the dataset
ds = pd.read_json(file_path)

# Use display for better formatting
display(ds)
Key Points:
display(ds) gives you the same nicely formatted table that you see when you type ds in a Jupyter notebook.
print(ds) will output the DataFrame as plain text, which might not look as nice.





You said:
parent_selection_type=parent_selection_type,
    crossover_type=crossover_type,
    mutation_type=mutation_type,

what options i have here?
ChatGPT said:
ChatGPT
Here are the options available for parent_selection_type, crossover_type, and mutation_type in PyGAD:

1. parent_selection_type
Determines how parents are selected for mating in the Genetic Algorithm. The options are:

"sss" (Stochastic Sampling Selection): Parents are selected based on their fitness proportionally.
"rws" (Roulette Wheel Selection): Similar to stochastic sampling but uses a probability wheel to select parents.
"sus" (Stochastic Universal Sampling): Ensures that parents are selected in proportion to their fitness values.
"rank": Parents are selected based on their rank (sorted fitness values).
"random": Randomly selects parents, regardless of fitness.
"tournament": Conducts a tournament among random individuals, and the best one is selected as a parent.
Customizable with K_tournament (default: 3): Specifies the number of individuals in each tournament.
2. crossover_type
Determines how genes are exchanged between parents during crossover. The options are:

"single_point": A single crossover point is chosen. Genes from the start to the crossover point are taken from one parent, and the rest from the other.
"two_points": Two crossover points are chosen. Genes between these points are swapped between parents.
"uniform": Each gene is randomly selected from one of the two parents with equal probability.
"scattered": A random binary mask determines which parent contributes each gene.
3. mutation_type
Determines how genes are mutated in the offspring. The options are:

"random": Randomly changes a gene to a new value within the gene's range. This is the most common type of mutation.
"swap": Swaps the values of two randomly chosen genes in the chromosome (useful for ordering problems like TSP).
"inversion": Reverses the order of a subset of genes (useful for ordering problems).
"scramble": Randomly rearranges the values of a subset of genes in the chromosome.
Example Configuration:
python
Copy code
parent_selection_type="tournament",  # Uses tournament selection
crossover_type="two_points",         # Two-point crossover
mutation_type="random"               # Random mutation
These options let you tailor the behavior of the genetic algorithm for your specific problem.








You said:
whats a good number for an initial population and whats a good number for the parents mating parameter
ChatGPT said:
ChatGPT
The optimal values for initial population size and number of parents mating depend on the complexity of your problem and computational resources. However, here are some guidelines:

1. Initial Population Size
This determines the diversity of solutions explored in the search space. A good starting range for most problems is:

Small problems (few variables or constraints): 20-50
Moderate problems: 50-200
Large or complex problems: 200-500
Considerations:

Larger populations increase diversity but take longer to compute.
Smaller populations may converge quickly but risk getting stuck in local optima.
For your problem:

Start with 50-100 individuals if the assignment matrix is small (e.g., 10x10 or 20x20).
Scale up if you notice poor diversity in solutions or premature convergence.
2. Number of Parents Mating
This controls how many parents are selected for generating offspring.

Typical Range:

20-50% of the population size (e.g., if population size is 100, parents mating could be 20-50).
Guidelines:

More mating parents ensure better genetic diversity in offspring.
Fewer mating parents can make the search more focused but may reduce diversity.
For your problem:

If population size is 50, try 10-20 parents mating.
For larger populations (e.g., 200), consider 30-60 mating parents.
3. Choosing Values Based on Goals
If you want diversity:
Use a larger population and allow more parents to mate.
If you want faster convergence:
Use a smaller population and fewer parents mating.
Suggested Starting Values
For a moderate-sized problem (e.g., 50 genes, assignment matrix of 10x10):

Population size: 100
Parents mating: 20
How to Experiment
Start with moderate values like population_size=100 and parents_mating=20.
Monitor:
Fitness values: Check if they're improving consistently across generations.
Convergence: If results stagnate too early, increase population size or mating parents.
Adjust:
If diversity is low, increase population size or parents mating.
If convergence is slow, decrease population size or parents mating.
By tuning these parameters, you'll find a balance between exploration (diversity) and exploitation (convergence). Let me know if you need help analyzing your results!

how can i generate a matrix that this function will return smallest number possible for that matrix if is an argument assignment?

def fitness_function_impl(assignment, preferences, capacity, min_reviews, max_reviews, friendships, authorship):
    # Total Preference Score
    preference_score = np.sum(assignment * preferences)
    max_preference_score = np.sum(np.max(preferences, axis=0))  # Max possible score
    normalized_preference_score = preference_score / max_preference_score

    # Capacity Violation
    capacity_violation = np.sum(np.maximum(0, np.sum(assignment, axis=1) - capacity))

    # Review Violations
    reviews_per_paper = np.sum(assignment, axis=0)
    review_violation = np.sum(np.maximum(0, min_reviews - reviews_per_paper)) + \
                       np.sum(np.maximum(0, reviews_per_paper - max_reviews))

    # Friendship Joint Review Violation
    friendship_violation = 0
    for i in range(len(friendships)):
        for j in range(len(friendships)):
            if friendships[i][j] == 1:
                friendship_violation += np.sum(assignment[i] * assignment[j])

    # Friends Reviewing Each Other's Papers
    friends_authorship_violation = 0
    num_reviewers, num_papers = assignment.shape
    for reviewer in range(num_reviewers):
        for paper in range(num_papers):
            for friend in range(num_reviewers):
                if friendships[reviewer][friend] == 1 and authorship[friend][paper] == 1:
                    friends_authorship_violation += assignment[reviewer][paper]

    # Authorship Violation
    authorship_violation = np.sum(assignment * authorship)

    # Weights for penalties
    w1, w2, w3, w4, w5 = 2, 3, 2, 3, 4  # Adjusted weights

    # Fitness
    fitness = normalized_preference_score - (w1 * capacity_violation + w2 * review_violation +
                                             w3 * friendship_violation + w4 * friends_authorship_violation +
                                             w5 * authorship_violation)

    # Bias towards non-zero assignments
    bias_reward = 0.01 * np.sum(assignment)  # Small reward for assignments
    fitness += bias_reward

    return fitness / (num_reviewers * num_papers)

ChatGPT said:
ChatGPT
To generate a matrix that minimizes the fitness value returned by the fitness_function_impl, we need to create an assignment matrix that satisfies as many constraints as possible and avoids penalties. Here's how you could approach generating such a matrix step-by-step:

1. Understand the Constraints and Penalties
Preference Score: Higher preference values in the preferences matrix should be favored, but this is secondary to avoiding penalties.
Capacity Violation: Ensure that the sum of assigned reviews for each reviewer does not exceed the capacity for any reviewer.
Review Violations: Each paper must have a number of reviewers between min_reviews and max_reviews.
Friendship Violations: Friends should not review the same papers or review papers authored by their friends.
Authorship Violations: Reviewers should not be assigned to papers they authored.
2. Define the Problem Variables
assignment: A binary matrix where assignment[i][j] = 1 if reviewer i reviews paper j, and 0 otherwise.
3. Approach for Generating the Matrix
Start with an empty assignment matrix (all zeros).
Iteratively assign reviewers to papers while avoiding violations:
Ensure each reviewer does not exceed their capacity.
Ensure each paper has reviewers within the min_reviews to max_reviews range.
Avoid assigning friends to the same paper.
Avoid assigning a reviewer to a paper authored by themselves or their friends.
4. Algorithm for Generating the Matrix
Here's a possible implementation in Python:

python
Copy code
import numpy as np

def generate_minimal_assignment(preferences, capacity, min_reviews, max_reviews, friendships, authorship):
    num_reviewers, num_papers = preferences.shape
    assignment = np.zeros((num_reviewers, num_papers), dtype=int)
    reviews_per_paper = np.zeros(num_papers, dtype=int)
    reviews_per_reviewer = np.zeros(num_reviewers, dtype=int)

    # Assign papers to reviewers
    for paper in range(num_papers):
        # Assign reviewers to this paper until min_reviews is met
        potential_reviewers = np.argsort(-preferences[:, paper])  # High preference reviewers first
        assigned_reviewers = 0
        for reviewer in potential_reviewers:
            # Check constraints
            if reviews_per_reviewer[reviewer] < capacity and \
               reviews_per_paper[paper] < max_reviews and \
               authorship[reviewer][paper] == 0 and \
               all(friendships[reviewer][friend] == 0 or authorship[friend][paper] == 0 for friend in range(num_reviewers)):
                # Assign the reviewer to the paper
                assignment[reviewer][paper] = 1
                reviews_per_reviewer[reviewer] += 1
                reviews_per_paper[paper] += 1
                assigned_reviewers += 1

                # Stop if we've met min_reviews for this paper
                if assigned_reviewers >= min_reviews:
                    break

    return assignment

# Example usage:
preferences = np.array([[3, 1], [2, 3], [1, 2]])  # Example preferences
capacity = np.array([2, 2, 2])  # Each reviewer can review up to 2 papers
min_reviews = 1
max_reviews = 2
friendships = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]])  # Reviewer 0 and 1 are friends, etc.
authorship = np.array([[1, 0], [0, 1], [0, 0]])  # Reviewer 0 authored paper 0, etc.

assignment = generate_minimal_assignment(preferences, capacity, min_reviews, max_reviews, friendships, authorship)
print("Generated Assignment Matrix:")
print(assignment)
5. Test and Refine
Run the fitness function on the generated matrix and verify its value. If the fitness is not minimal, refine the algorithm:

Try different strategies for reviewer selection.
Incorporate optimization techniques like simulated annealing or genetic algorithms for better assignment.
This approach provides a feasible starting point for generating a matrix to minimize the fitness value.





You said:
but with this function i will always get the same solution, i want to have more different solutions but similar
ChatGPT said:
ChatGPT
To generate diverse solutions while keeping them similar, you can introduce randomness and constraints to explore the solution space. The key idea is to apply a controlled degree of variation to the assignment matrix while ensuring it remains feasible.

Here’s how you can approach it:

1. Introduce Randomness
Shuffle the order in which reviewers are considered for assignment.
Randomly break ties when multiple reviewers have similar preferences for a paper.
Randomly skip or prioritize some valid assignments during each run.
2. Enforce Similarity
Keep track of a baseline solution.
Allow variations that slightly deviate from the baseline solution.
Introduce a threshold for similarity (e.g., a percentage of assignments that must match the baseline).
3. Algorithm with Randomness
Here’s an updated version of the algorithm to include randomness:

python
Copy code
import numpy as np

def generate_randomized_assignments(preferences, capacity, min_reviews, max_reviews, friendships, authorship, baseline=None, similarity_threshold=0.8):
    num_reviewers, num_papers = preferences.shape
    assignment = np.zeros((num_reviewers, num_papers), dtype=int)
    reviews_per_paper = np.zeros(num_papers, dtype=int)
    reviews_per_reviewer = np.zeros(num_reviewers, dtype=int)

    # Randomly shuffle the order of papers
    papers = np.arange(num_papers)
    np.random.shuffle(papers)

    for paper in papers:
        # Assign reviewers to this paper until min_reviews is met
        potential_reviewers = np.argsort(-preferences[:, paper])  # High preference reviewers first
        np.random.shuffle(potential_reviewers)  # Randomize potential reviewers order
        assigned_reviewers = 0

        for reviewer in potential_reviewers:
            # Check constraints
            if reviews_per_reviewer[reviewer] < capacity and \
               reviews_per_paper[paper] < max_reviews and \
               authorship[reviewer][paper] == 0 and \
               all(friendships[reviewer][friend] == 0 or authorship[friend][paper] == 0 for friend in range(num_reviewers)):
                # Assign the reviewer to the paper
                assignment[reviewer][paper] = 1
                reviews_per_reviewer[reviewer] += 1
                reviews_per_paper[paper] += 1
                assigned_reviewers += 1

                # Stop if we've met min_reviews for this paper
                if assigned_reviewers >= min_reviews:
                    break

    # Ensure similarity to baseline if provided
    if baseline is not None:
        total_assignments = num_reviewers * num_papers
        max_allowed_differences = total_assignments * (1 - similarity_threshold)
        differences = np.sum(assignment != baseline)

        if differences > max_allowed_differences:
            return generate_randomized_assignments(preferences, capacity, min_reviews, max_reviews, friendships, authorship, baseline, similarity_threshold)

    return assignment

# Example usage:
preferences = np.array([[3, 1], [2, 3], [1, 2]])  # Example preferences
capacity = np.array([2, 2, 2])  # Each reviewer can review up to 2 papers
min_reviews = 1
max_reviews = 2
friendships = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]])  # Reviewer 0 and 1 are friends, etc.
authorship = np.array([[1, 0], [0, 1], [0, 0]])  # Reviewer 0 authored paper 0, etc.

# Generate a baseline solution
baseline_assignment = generate_randomized_assignments(preferences, capacity, min_reviews, max_reviews, friendships, authorship)

# Generate a similar but different solution
randomized_assignment = generate_randomized_assignments(preferences, capacity, min_reviews, max_reviews, friendships, authorship, baseline=baseline_assignment, similarity_threshold=0.9)

print("Baseline Assignment:")
print(baseline_assignment)
print("\nRandomized Assignment:")
print(randomized_assignment)
4. Key Features
Controlled Randomness:

Randomly shuffle reviewers and papers to create different starting points.
Randomly skip some assignments or change tie-breaking criteria.
Similarity Constraint:

Compare the new assignment matrix to the baseline.
Ensure that the number of differing elements does not exceed a threshold (e.g., 10%).
Iterative Refinement:

If the new matrix violates the similarity threshold, regenerate the assignment.
5. Further Enhancements
Weight Adjustments: Slightly perturb the preference weights or constraints for additional variability.
Diversity Optimization: Use a genetic algorithm or simulated annealing to maximize diversity while satisfying constraints.
Multi-Solution Sampling: Generate multiple solutions and select a diverse subset using a clustering method.
This approach allows you to generate varied yet feasible assignment matrices similar to a baseline solution.

average_heuristic_authorship = average_heuristic_authorship/100
average_heuristic_friendship = average_heuristic_friendship/100
average_heuristic_row_wise = average_heuristic_row_wise/100
average_heuristic_column_wise = average_heuristic_column_wise/100
average_heuristic_block = average_heuristic_block/100
average_heuristic_swap = average_heuristic_swap/100

average_matrix_authorship = average_matrix_authorship/100
average_matrix_friendship = average_matrix_friendship/100
average_matrix_row_wise = average_matrix_row_wise/100
average_matrix_column_wise = average_matrix_column_wise/100
average_matrix_block = average_matrix_block/100
average_matrix_swap = average_matrix_swap/100

average_two_point_authorship = average_two_point_authorship/100
average_two_point_friendship = average_two_point_friendship/100
average_two_point_row_wise = average_two_point_row_wise/100
average_two_point_column_wise = average_two_point_column_wise/100
average_two_point_block = average_two_point_block/100
average_two_point_swap = average_two_point_swap/100

prite me code so i can print these
ChatGPT said:
ChatGPT
Here’s the Python code to print these values in a formatted manner:

Print Average Metrics
This function organizes and prints the averages into three clear sections: heuristic values, matrix values, and two-point values. You can copy and paste this function into your script to display the averages.





You said:
write me the same for these:

average_columns_authorship = average_columns_authorship / 100
average_columns_friendship = average_columns_friendship / 100
average_columns_rows = average_columns_rows / 100
average_columns_columns = average_columns_columns / 100
average_columns_block = average_columns_block / 100
average_columns_swap = average_columns_swap / 100

average_rows_authorship = average_rows_authorship / 100
average_rows_friendship = average_rows_friendship / 100
average_rows_rows = average_rows_rows / 100
average_rows_columns = average_rows_columns / 100
average_rows_block = average_rows_block / 100
average_rows_swap = average_rows_swap / 100

average_uniform_authorship = average_uniform_authorship / 100
average_uniform_friendship = average_uniform_friendship / 100
average_uniform_rows = average_uniform_rows / 100
average_uniform_columns = average_uniform_columns / 100
average_uniform_block = average_uniform_block / 100
average_uniform_swap = average_uniform_swap / 100
ChatGPT said:
ChatGPT
Edited
I've added print statements for the averages of columns, rows, and uniform values to the existing function. Let me know if you need further adjustments or additions!





You said:
i also want to visualise thsese values
ChatGPT said:
ChatGPT
Print Average Metrics
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
import matplotlib.pyplot as plt

# Print the averaged values for heuristics
def print_averages():
    print("\n--- Average Heuristic Values ---")
    print(f"Authorship: {average_heuristic_authorship:.2f}")
    print(f"Friendship: {average_heuristic_friendship:.2f}")
    print(f"Row-wise: {average_heuristic_row_wise:.2f}")
    print(f"Column-wise: {average_heuristic_column_wise:.2f}")
    print(f"Block: {average_heuristic_block:.2f}")
    print(f"Swap: {average_heuristic_swap:.2f}")

    # Print the averaged values for matrix
    print("\n--- Average Matrix Values ---")
    print(f"Authorship: {average_matrix_authorship:.2f}")
    print(f"Friendship: {average_matrix_friendship:.2f}")
    print(f"Row-wise: {average_matrix_row_wise:.2f}")
    print(f"Column-wise: {average_matrix_column_wise:.2f}")
    print(f"Block: {average_matrix_block:.2f}")
    print(f"Swap: {average_matrix_swap:.2f}")

    # Print the averaged values for two-point
    print("\n--- Average Two-Point Values ---")
    print(f"Authorship: {average_two_point_authorship:.2f}")
    print(f"Friendship: {average_two_point_friendship:.2f}")
    print(f"Row-wise: {average_two_point_row_wise:.2f}")
    print(f"Column-wise: {average_two_point_column_wise:.2f}")
    print(f"Block: {average_two_point_block:.2f}")
    print(f"Swap: {average_two_point_swap:.2f}")

# Visualize the averaged values
def visualize_averages():
    categories = ["Authorship", "Friendship", "Row-wise", "Column-wise", "Block", "Swap"]

    heuristic_values = [
        average_heuristic_authorship,
        average_heuristic_friendship,
        average_heuristic_row_wise,
        average_heuristic_column_wise,
        average_heuristic_block,
        average_heuristic_swap
    ]

    matrix_values = [
        average_matrix_authorship,
        average_matrix_friendship,
        average_matrix_row_wise,
        average_matrix_column_wise,
        average_matrix_block,
        average_matrix_swap
    ]

    two_point_values = [
        average_two_point_authorship,
        average_two_point_friendship,
        average_two_point_row_wise,
        average_two_point_column_wise,
        average_two_point_block,
        average_two_point_swap
    ]

    x = range(len(categories))

    plt.figure(figsize=(12, 6))

    plt.plot(x, heuristic_values, marker='o', label='Heuristic')
    plt.plot(x, matrix_values, marker='s', label='Matrix')
    plt.plot(x, two_point_values, marker='^', label='Two-Point')

    plt.xticks(x, categories)
    plt.xlabel("Categories")
    plt.ylabel("Average Values")
    plt.title("Visualization of Average Values")
    plt.legend()
    plt.grid(True)

    plt.show()

# Call the function to display the results
print_averages()
visualize_averages()

Edited
I have added a visualization function using Matplotlib to plot the average values for heuristics, matrix, and two-point configurations. You can now visualize these values with line plots to better analyze the differences across categories. Let me know if further adjustments or enhancements are needed!

